# DEEP LEARNING SPECIALIZATION
- By Andrew Ng Offered by DeepLearning.AI
<hr/>

## COURSE 1 : [NEURAL NETWORKS AND DEEP LEARNING](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/01_Neural%20Networks%20and%20Deep%20Learning)
- Week 01 : [Introduction to Deep Learning](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/01_Neural%20Networks%20and%20Deep%20Learning/W01_Introduction%20to%20Deep%20Learning)
    1. [Introduction to Deep Learning](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W01_Introduction%20to%20Deep%20Learning/01_Introduction%20to%20Deep%20Learning.ipynb)
        - What we'll learn
        - What is a Neural Network
        - Supervised Learning with Neural Networks
        - Why is Deep Learning taking off?
</br>

- Week 02 : [Neural Network Basics](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/01_Neural%20Networks%20and%20Deep%20Learning/W02_Neural%20Network%20Basics)
    1. [Logisitic Regression as a Neural Network](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W02_Neural%20Network%20Basics/01_Logistic%20Regression%20as%20a%20Neural%20Network.ipynb)
        - Binary Classification
        - Logistic Regression
        - Logistic Regression Cost Function
        - Gradient Descent
        - Logisitic Regression Gradient Descent
        - Gradient Descent of m examples.
    2. [Python and Vectorization](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W02_Neural%20Network%20Basics/02_Python%20and%20Vectorization.ipynb)
        - Vectorization
        - Vectorization Logisitic Regression
        - Vectorizing Logisitic Regression's Gradient
        - BroadCasting in Python
        - Logisitic Regression cost function
    3. [Assignment : Python Basics with Numpy](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W02_Neural%20Network%20Basics/01_Assignment%20%20Python%20Basics%20with%20Numpy.ipynb)
        - Building Basic function with numpy
        - Sigmoid function
        - Reshaping Arrays
        - Normalizing rows
        - Softmax
        - Vectorization L1 and L2 Loss
    4. [Assignment : Logistic Regression with Neural Networks](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W02_Neural%20Network%20Basics/02_Assignment%20Logistic%20Regression%20with%20Neural%20Networks.ipynb)
        - Image-recognition that classify pictures as cat or non-cat.
</br>

- Week 03 : [Shallow Neural Networks](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/01_Neural%20Networks%20and%20Deep%20Learning/W03_Shallow%20Neural%20Networks)
    1. [Shallow Neural Network](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W03_Shallow%20Neural%20Networks/01_Shallow%20Neural%20Network.ipynb)
        - Neural Networks Overview
        - Neural Network Representation
        - Computinng a Neural Network's Output
        - Vectorization across multiple Examples
        - Explanation for vectorized implementation
        - Activation function
        - Why do we need non-linear activaton functions
        - Derivatives of activation functions
        - Gradient descent for neural networks
        - Backpropagation inutition
        - Random initialization
    2. [Assignment : Planar Data classification with one hidden layer](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W03_Shallow%20Neural%20Networks/01_Assignment%20Planar%20Data%20Classification%20with%20One%20Hidden%20Layer.ipynb)
</br>

- Week 04 : [Deep Neural Networks](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/01_Neural%20Networks%20and%20Deep%20Learning/W04_Deep%20Neural%20Networks)
    1. [Deep Neural Network](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W04_Deep%20Neural%20Networks/01_Deep%20Neural%20Network.ipynb)
        - Deep L-layer neural network
        - Deep neural network notation
        - Forward propagation in a deep network
        - Getting our matrix dimensions right
        - Why deep representations
        - Building blocks of deep neural networks
        - Forward and Backward propagation
        - Parameters vs Hyperparameters
    2. [Assignment : Building our Deep Neural Network - Step by Step](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W04_Deep%20Neural%20Networks/01_Assignment%20Buidling%20our%20Deep%20Neural%20Network.ipynb)
    3. [Assignment : Deep Neural Network for Image Classification : Application](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/01_Neural%20Networks%20and%20Deep%20Learning/W04_Deep%20Neural%20Networks/02_Assignment%20Deep%20Neural%20Network%20-%20Application.ipynb)
        - Cat/not cat classifier

#### [Certificate of Completion](https://www.coursera.org/account/accomplishments/verify/OM3AFF5VZJ8U)

## COURSE 2 : [IMPROVING DEEP NN HYPERPARAMETER TUNING, REGULARIZATION AND OPTIMIZATION](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization)
- Week 01 : [Practical Aspects of Deep Learning](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning)
    1. [Setting up our ML application](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning/01_Setting%20up%20our%20Machine%20Learning%20Application.ipynb)
        - Train/Dev/Test sets
        - Bias/Variance
        - Basic Recipe for ML
    2. [Regularizing our Neural Network](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning/02_Regularizing%20our%20Neural%20Network.ipynb)
        - Regularization
        - Logistic Regression
        - Neural Network
        - Why Regularization Reduces Overfitting
        - Dropout Regularization
        - Understanding Dropout
        - Data Augmentation
        - Early Stopping
    3. [Setting up our optimization problem](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning/03_Setting%20up%20our%20Optimization%20Problem.ipynb)
        - Normalizing inputs
        - Vanishing/Exploding Gradients
        - Weight initialization for deep networks
        - Numerical Approximation of Gradients
        - Gradient Checking
        - Gradient checking implementation notes
    4. [Assignment : Initilization](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning/01_Assignment%20Initialization.ipynb)
    5. [Assignment : Regularization](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning/02_Assignment%20Regularization.ipynb)
    6. [Assignment : Gradient Checking](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W01_Practical%20Aspects%20of%20Deep%20Learning/03_Assignment%20Gradient%20Checking.ipynb)
        - Fraud Detection whenever someone makes a payment
</br>

- Week 02 : [Optimization Algorithm](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W02_Optimization%20Algorithm)
    1. [Optimization Algorithms](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W02_Optimization%20Algorithm/01_Optimization%20Algorithms.ipynb)
        - Mini-batch Gradient Descent
        - Understanding mini-batch gradient descent
        - Choosing our mini-batch size
        - Exponentially weighted averages
        - Bias correction in exponentially weighted averages
        - Gradient descent with momentum
        - RMSProp
        - Adam Optimization Algorithm
        - Learning Rate Decay
        - The problem of local optima
    2. [Assignment : Optimization Methods](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W02_Optimization%20Algorithm/02_Assignment%20Optimization%20Methods.ipynb)
</br>

- Week 03 : [Hyperparameter Tuning, Batch Normalization and Programming Framework](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W03_Hyperparameter%20Tuning%2C%20Batch%20Normalization%20and%20Programming%20Framework)
    1. [Hyperparameter Tuning](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W03_Hyperparameter%20Tuning%2C%20Batch%20Normalization%20and%20Programming%20Framework/01_Hyperparameter%20Tuning.ipynb)
        - Tuning Process
        - Using an appropriate scale to pick hyperparamters
        - Hyperparameter tuning in practice : Pandas vs Caviar
    2. [Batch Normalization](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W03_Hyperparameter%20Tuning%2C%20Batch%20Normalization%20and%20Programming%20Framework/02_Batch%20Normalization.ipynb)
        - Normalizing Activations in a network
        - Fitting Batch Norm into a Neural Network
        - Why does batch norm work
        - Batch norm at test
    3. [Multi-class Classification](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W03_Hyperparameter%20Tuning%2C%20Batch%20Normalization%20and%20Programming%20Framework/03_Multi%20Class%20Classification.ipynb)
        - Softmax Regression
        - Train a softmax classifier
    4. [Intro to Programming Framework](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W03_Hyperparameter%20Tuning%2C%20Batch%20Normalization%20and%20Programming%20Framework/04_Intro%20to%20Programming%20Framework.ipynb)
        - Deep Learning Frameworks
        - Tensorflow
    5. [Assignment : Tensorflow](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/02_Improving%20Deep%20NN%20%20Hyperparameter%20Tuing%2C%20Regularization%20and%20optimization/W03_Hyperparameter%20Tuning%2C%20Batch%20Normalization%20and%20Programming%20Framework/01_Assignment%20TensorFlow.ipynb)

#### [Certificate of Completion](https://www.coursera.org/account/accomplishments/verify/FHYV1UEZ77W1)
</br>
</br>

## COURSE 3 : [STRUCTURING ML PROJECTS](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/03_Structuring%20ML%20Projects)
- Week 01 : [ML Strategy](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/03_Structuring%20ML%20Projects/W01_ML%20Strategy)
    1. [Intro to ML Strategy](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W01_ML%20Strategy/01_Intro%20to%20ML%20Strategy.ipynb)
        - Why ML Strategy
        - Orthogonalization
    2. [Setting up our Goal](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W01_ML%20Strategy/02_Setting%20Up%20our%20Goal.ipynb)
        - Single Number Evaluation Metric
        - Satisficing and optimizing metric
        - Train/Dev/Tes Distribution
        - Size of the dev and Test sets
        - When to change Dev/Test sets and metrics
    3. [Comparing to Human Level Performance](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W01_ML%20Strategy/03_Comparing%20to%20Human%20level%20Performance.ipynb)
        - Why human-level performance
        - Avoidable Bias
        - Understanding human-level performance
        - Surpassing human-level performance
        - Improving our model performance
- Week 02 : [ML Strategy](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/tree/main/03_Structuring%20ML%20Projects/W02_ML%20Strategy)
    1. [Error Analysis](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W02_ML%20Strategy/01_Error%20Analysis.ipynb)
        - Carrying out error analysis
        - Evaluate multiple ideas in parallel
        - Cleaning up incorrectly labeled data
        - Error analysis
        - build our first system quickly, then iterate
    2. [Mismatched Training and Dev Test set](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W02_ML%20Strategy/02_Mismatched%20Training%20and%20Dev%20Test%20set.ipynb)
        - Training and Testing on Different Distribution
        - Bias and Variance with mismatched data distribution
        - Addressing Data Mismatch
    3. [Learning from Multiple Tasks](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W02_ML%20Strategy/03_Learning%20from%20Multiple%20Tasks.ipynb)
        - Transfer Learning
        - Multi-task Learning
    4. [End to End Deep Learning](https://github.com/ssmaheswar2001/Deep_Learning_Specialization_Coursera/blob/main/03_Structuring%20ML%20Projects/W02_ML%20Strategy/04_End%20to%20End%20Deep%20Learning.ipynb)
        - What is End-to-End Deep Learning
        - Whether to use End-to-End Deep Learning

#### [Certificate of Completion](https://www.coursera.org/account/accomplishments/verify/92QPSG92NKZ7)
</br>
</br>


## COURSE 4 : [CONVOLUTIONAL NEURAL NETWORK]()


## COURSE 5 : [SEQUENCE MODELS]()